{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df94c90",
   "metadata": {},
   "source": [
    "# AFRICAN INSTITUTE FOR MATHEMATICAL SCIENCES\n",
    "## (AIMS RWANDA, KIGALI)\n",
    "\n",
    "---\n",
    "\n",
    "**Name:** Vincent ONDENG  \n",
    "**Course:** BIG DATA ANALYTICS WITH PYTHON\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e5672",
   "metadata": {},
   "source": [
    "# ML with Large Datasets\n",
    "----\n",
    "## Dataset Description\n",
    "In order to explore these Spark API, we use the [following dataset](). The data is from a population and housing census of some country ```X```  not identified for privacy reasons although this data is a very small subset of the actual data. \n",
    "Each row in the data represent a single individual in the population. \n",
    " A summary of column description is provided below:\n",
    "- **Geographic identifiers:** PROVINCE, REGION, DISTRICT, COMMUNE,MILIEU ,\n",
    "       IDMEN, IDINDIV. This type of data has a somewhat hierarchical structure. We have a household (think of it as family), IDMEN-household ID. Within each household, we have individuals, IDINDIV - individual\n",
    "       > \n",
    "- **MILIEU:** A classification of whether this person lived in urban or rural area. ```2-Rural, 1-Urban```\n",
    "- **Sex**. ```P05```==>[1\t- Male 2\t- Female]\n",
    "- **P19 Languages spoken**. What languages the person can speak.This variable is split into 4 variables as follows: ```P19MG, P19FR, P19AN, P19AU``` for local language, English, French and any other language.\n",
    "- **P20, Literacy**. Whether the person can read and write any of the 3 languages given. Note that there three variables each representing each language. A local language, French and English. For each language, the value 1 means they can read and write in the language while 2 means they cannot.The variables are ```P20MG (local language), P20FR (French), P20AN (English), P20AU (other)```. \n",
    "- **P03:** whether the person is the head of the household, wife. child etc==>[0- Chef de Ménage (CM) 1- Conjoint(e) (CJ) 2-\tFils/Fille3-\tPère/Mère 4-\tBeau-Père/Belle-Mère 5-\tBeau-Fils/Belle-Fille 6-\tPetit fils/Petite-fille\n",
    " Autre Proche du CM 8- Autre proche du CJ 9 -Sans lien de parenté]\n",
    "\n",
    "- **Age:**. Person's date of birth is given by column ```P07M``` (month of birth), ```P07A``` (year of birth) and ```P08``` (age)\n",
    "- **Marital status:** ```P28``` (whether the person is married or not)==>[1-\tCélibataire, 2-\tMarié(e), 3-\tDivorcé(e)/Séparé(e), 4-\tVeuf(ve)]. This question is asked to residents who are 12 years or older. \n",
    "- **Age at first marriage**. ```P29``` (age at marriage).The question was like this: How old was <NAME> when he/she got married for the first time?\n",
    "- **School attendance:** ```P21``` ==>[0 N'a Jamais fréquenté 1-A\tfréquenté 2- Fréquente actuellement]\n",
    "- **Highest school level attended:**```P22N```. This variable represents highest level of school attended. The question was asked like this: What is the highest level of education that (name) achieved during his studies?\n",
    " > 1. Preschool; 2. Primary-school; 3. Secondary; 4. Technical college; 5. University \n",
    " - **Number of years of school completed at a particular level:** ```P22C``` Years completed at that level. A value of 0 means the person didnt complete the first year of education at that level. \n",
    " > Preschool(0-2); Primary-school(0-5);Secondary(0-7); Technical college (0-7); University (0-7)\n",
    " \n",
    "- **Whether the person worked or not:** ```P23```==> [1-\t0ccupé 2-\tChômeur 3-\tEn quête du 1er emploi 4-\tMénagère 5-\tElève/Etudiant 6-\tRetraité 7- lncapacité à travailler 8- Autre]\n",
    "\n",
    "## The Task\n",
    "The Ministry of Health in the country has expressed concern about the prevalence of early marriages among young individuals (both men and women). They have tasked you with investigating the factors contributing to early marriages. For the purpose of this analysis, individuals who get married at the age of 18 or younger are classified as having married early or belonging to the early marriage category. Beyond conducting exploratory analysis, the Ministry has requested that you develop a model to predict whether a person is likely to marry young, based on factors such as place of residence, household size, parents' education levels, and other relevant variables. In summary, these are the project goals.\n",
    "1. Perfom explotaory analysis to understand early marriages \n",
    "2. Build a Machine Learning model which can predict whether a person will get married early or not.\n",
    "3. Report on the model performance and efficacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158d5d8d-0607-46ca-903a-76f2f82e8c48",
   "metadata": {},
   "source": [
    "## Python setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1d9b8d-59e7-400a-b427-701780ce2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python setup\n",
    "from datetime import datetime\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "# Suppress scientific notation globally\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RF, GradientBoostingClassifier as GBM, ExtraTreesClassifier as ETC, AdaBoostClassifier as Ada\n",
    "from sklearn.metrics import accuracy_score, classification_report, accuracy_score\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf01fa1-c3cb-4cd0-afaf-125459dc563b",
   "metadata": {},
   "source": [
    "# Inputs Paths, Global Variables and Parameters\n",
    "Lets provide paths to input files we will use. \n",
    "Its a good practice to create these as global variables. Also, use Python module ```Path``` from pathlib to manage file paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa670af-ffd2-4b5c-9c6d-3ef9edf713ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to hh_data.txt\n",
    "HH_DATA = \"ResidentIBEIPM.csv\"\n",
    "\n",
    "# Decide which columns to keep\n",
    "COLS_TO_KEEP = ['PROVINCE','REGION','DISTRICT','COMMUNE','MILIEU', 'IDMEN',\n",
    "                    'IDINDIV','P08','P28','P23','P03', 'P22N','P22C','P21','P29','P05',\n",
    "                    'P19MG','P19FR','P19AN','P19AU', 'P20MG', 'P20FR', 'P20AN', 'P20AU']\n",
    "\n",
    "# Regular household size threshold\n",
    "# use quintiles to determine the threshold\n",
    "HH_SIZE_THRESHOLD = 0.99\n",
    "\n",
    "# CHILFREN AGE THRESHOLD\n",
    "CHILDREN_AGE_THRESHOLD = 15\n",
    "ELDERY_AGE_THRESHOLD = 65\n",
    "EARLY_MARRIAGE_AGE_THRESHOLD = 18    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-register",
   "metadata": {},
   "source": [
    "# Task 1 - Loading and Subsetting the Data\n",
    "## Strategy\n",
    "To efficiently load and work with data, I began by setting up a Spark session using 8 cores to facltate faster operations. I allocated 4GB of memory for both the driver and executor, and enabled off-heap memory to handle larger datasets effectively. The number of shuffle partitions was set to 40, balancing parallelism with performance. I loaded the dataset using Spark’s read.csv() function, ensuring that Spark automatically inferred the schema and processed the CSV file with a comma delimiter. To optimize processing, I filtered the data down to just the columns I needed using the select() function.\n",
    "\n",
    "\n",
    "To enhance processing efficiency, I repartitioned the DataFrame into 10 partitions, ensuring the workload was distributed well across available resources. After processing, I coalesced the DataFrame into a single partition to minimize the number of output files when writing the data back to disk.\n",
    "\n",
    "Finally, I wrote the processed data to a new CSV file, using the overwrite mode to replace any previous output, ensuring that the final dataset was ready for preprocessing.\n",
    "\n",
    "This approach allowed me to balance memory usage, parallel processing, and disk I/O effectively, ensuring smooth handling of the large csv while keeping perfomance optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063ad06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                .appName(\"LargeDatasetProcessing\")\\\n",
    "                .master(f\"local[8]\")\\\n",
    "                .config(\"spark.driver.memory\", \"4g\")\\\n",
    "                .config(\"spark.executor.memory\", \"4g\")\\\n",
    "                .config(\"spark.memory.offHeap.enabled\", \"true\")\\\n",
    "                .config(\"spark.sql.shuffle.partitions\", \"40\")\\\n",
    "                .config(\"spark.memory.offHeap.size\", \"1g\")\\\n",
    "                .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a932562",
   "metadata": {},
   "source": [
    "# Preprocess the Data\n",
    "\n",
    "The objective here is to load the dataset, retain only the necessary columns to reduce its size, and enable faster processing. During preprocessing, we aim to clean up the columns and convert numeric columns into proper numeric data types.\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "I use Spark for loading the data because it is faster than pandas. Alternatively, students can use the pandas \"chunk\" method to load data in manageable chunks. Another approach is to first load a small sample of the dataset, identify and document the required columns, and then load only those columns from the full dataset.\n",
    "\n",
    "## Subset the Columns\n",
    "\n",
    "Whether or not all columns were initially loaded, this step involves selecting only the required columns for further processing.\n",
    "\n",
    "## Preprocess and Clean Data\n",
    "\n",
    "For columns such as `age`, ensure they are in numeric format. Rows containing invalid or erroneous data can be removed as part of the cleaning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf53ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.csv(HH_DATA, header=True, sep=\",\", inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c637ab",
   "metadata": {},
   "source": [
    "## Subset the Data\n",
    "Keep only the columns we need and save a smaller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b325e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf2 = sdf.select(COLS_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7485ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition the DataFrame to 10 partitions\n",
    "out_csv = \"hh_data_subset\"\n",
    "\n",
    "sdf2.repartition(10).coalesce(1).write.csv(out_csv, header=True, sep=\",\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-innocent",
   "metadata": {},
   "source": [
    "# Task 2 - Data Preprocessing\n",
    "## Strategy\n",
    "The goal of this task \n",
    "is to transform the raw data into a clean, structured and feature rich dataset that can be effectively used to build a machine learning model. In this section, I focused on improving the data quality, handling missing values, and generating additional variables that will be crucial for building the model.\n",
    "\n",
    "Many machine learning models require categorical variables to be encoded as numeric values. I will apply the following techniques; For nominal categorical variables without an inherent order (e.g., gender, region), I will apply one-hot encoding to create binary features for each category, making the data suitable for most machine learning algorithms.\n",
    "\n",
    "Feature engineering is crucial to enhance the model's predictive power. During this step, I will create new features that capture important relationships within the data:\n",
    "Interaction features: I will combine existing features that may have a meaningful relationship. For example, I might create a new variable such as \"age x education level\" to capture the interaction between these two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb43e0f",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "- Rename columns for easy identification\n",
    "- Perform data type conversion if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef35ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Load the smaller CSV fwe just created as pandas DataFrame\n",
    "# ==========================================================\n",
    "df = pd.read_csv(\"hh_data_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "commercial-independence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PROVINCE', 'REGION', 'DISTRICT', 'COMMUNE', 'MILIEU', 'IDMEN',\n",
      "       'IDINDIV', 'P08', 'P28', 'P23', 'P03', 'P22N', 'P22C', 'P21', 'P29',\n",
      "       'P05', 'P19MG', 'P19FR', 'P19AN', 'P19AU', 'P20MG', 'P20FR', 'P20AN',\n",
      "       'P20AU'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = df.columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6865929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# RENAME COLUMNS\n",
    "# ====================================\n",
    "rename_mapping = {\n",
    "    'IDMEN' : 'hh_id',\n",
    "    'IDINDIV' : 'indiv_id',\n",
    "    'P08' : 'age',\n",
    "    'P28' : 'marital_status',\n",
    "    'P23' : 'working_status',\n",
    "    'P03' : 'head_household',\n",
    "    'P22N' : 'highest_education',\n",
    "    'P22C' : 'years_completed',\n",
    "    'P21' : 'school_attendance',\n",
    "    'P29' : 'age_at_marriage',\n",
    "    'P05' : 'sex',\n",
    "    'P19MG' : 'local_lnguage',\n",
    "    'P19FR' : 'french',\n",
    "    'P19AN' : 'english',\n",
    "    'P19AU' : 'other_language',\n",
    "    'P20MG' : 'local_language_literacy',\n",
    "    'P20FR' : 'french_literacy',\n",
    "    'P20AN' : 'english_literacy',\n",
    "    'P20AU' : 'other_language_literacy'   \n",
    "    }\n",
    "df.rename(columns=rename_mapping, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93658fd",
   "metadata": {},
   "source": [
    "### Add New Variables We Need\n",
    "\n",
    "In some cases, key information we need to explore may not be readily available in the dataset. For example, to analyze households, we might need to create a new column to represent household size.\n",
    "\n",
    "#### Household Size\n",
    "Household size refers to the number of people in a household. The dataset provides a household identifier (`hh_id`) and an individual identifier (`indiv_id`). Using these, we can generate a new column called `household_size`.\n",
    "\n",
    "#### Feature Engineering: Creating Additional Variables\n",
    "Feature engineering is the process of transforming raw data into meaningful features that improve the performance of machine learning models. This involves selecting, creating, modifying, or aggregating data attributes to make them more informative and relevant to the task at hand. Feature engineering is inherently a creative task—there are no strict rules. As a data scientist or machine learning practitioner, it's up to you to explore the data, consult domain experts, and study relevant literature to design and test new features.\n",
    "\n",
    "For this analysis, we can consider creating the following features, which may influence the age at first marriage:\n",
    "\n",
    "- **Number of dependent children in the household**: Defined as the number of individuals aged 15 and younger.\n",
    "- **Number of dependent adults in the household**: Defined as the number of individuals aged 65 and older.\n",
    "\n",
    "#### Household Level Variables \n",
    "Note that we have two levels of analysis units here: the individual and the household. As such, variables such as household size, number of children, number of the eldery are all household level variables. Since the head of the family or head of the household has more power in determing what happens in the house, we can also add household head variables. Concretely, for each household, we can have variables named like this: hoh_age, hoh_educ, hoh_literacy etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c19c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_var_hh_size(df, hh_id_col='hh_id'):\n",
    "    \"\"\"Generates variable hh_size\n",
    "\n",
    "    _extended_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : _type_\n",
    "        _description_\n",
    "    hh_id_col : str, optional\n",
    "        _description_, by default 'hh_id'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # ======================================================\n",
    "    # GENERATE HH SIZE\n",
    "    # ======================================================\n",
    "    \n",
    "    hh_size = df.groupby(hh_id_col)['indiv_id'].transform('count')\n",
    "    df['hh_size'] = hh_size    \n",
    "\n",
    "    # ======================================================\n",
    "    # GENERATE NUMBER OF CHILDREN AND ELDERLY\n",
    "    # ======================================================\n",
    "    # Create a column indicating whether an individual is a child using Child Age Threshold\n",
    "    df['is_child'] = df['age'] < CHILDREN_AGE_THRESHOLD\n",
    "    \n",
    "    # Create a column indicating whether an individual is elderly using Elderly age threshold\n",
    "    df['is_elderly'] = df['age'] >= ELDERY_AGE_THRESHOLD\n",
    "    \n",
    "    # Count the number of children and elderly in each household\n",
    "    num_children = df.groupby(hh_id_col)['is_child'].transform('sum')\n",
    "    num_elderly = df.groupby(hh_id_col)['is_elderly'].transform('sum')\n",
    "    \n",
    "    df['num_children'] = num_children\n",
    "    df['num_elderly'] = num_elderly  \n",
    "  \n",
    "    # ======================================================\n",
    "    # FILL NAs WITH 0\n",
    "    # ======================================================\n",
    "    df['num_children'].fillna(0, inplace=True)\n",
    "    df['num_elderly'].fillna(0, inplace=True)\n",
    "     \n",
    "    # ======================================================\n",
    "    # CHECK THAT WE HAVE ALL HH_ID\n",
    "    # ======================================================\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f4d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# ADD HOUSEHOLD LEVEL VARIABLES\n",
    "# ====================================\n",
    "# Household size\n",
    "df = gen_var_hh_size(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "planned-cursor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN count per column:\n",
      "PROVINCE                          0\n",
      "REGION                            0\n",
      "DISTRICT                          0\n",
      "COMMUNE                           0\n",
      "MILIEU                            0\n",
      "hh_id                             0\n",
      "indiv_id                          0\n",
      "age                             881\n",
      "marital_status              8630213\n",
      "working_status              3705803\n",
      "head_household                    0\n",
      "highest_education           7981271\n",
      "years_completed             7988558\n",
      "school_attendance           2165345\n",
      "age_at_marriage            15332430\n",
      "sex                               0\n",
      "local_lnguage               2165987\n",
      "french                      2166013\n",
      "english                     2166021\n",
      "other_language              2166030\n",
      "local_language_literacy     2165457\n",
      "french_literacy             2165466\n",
      "english_literacy            2165471\n",
      "other_language_literacy     2165489\n",
      "hh_size                           0\n",
      "is_child                          0\n",
      "is_elderly                        0\n",
      "num_children                      0\n",
      "num_elderly                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_nan_count = df.isnull().sum()\n",
    "print(\"NaN count per column:\")\n",
    "print(column_nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ca590",
   "metadata": {},
   "source": [
    "# Task 3 - Explolatory Data Analysis (EDA)\n",
    "Before any ML task, its important to understand the data. \n",
    "This is done by exploring the data to understand the data types, missing values, and the distribution of the data. This is important as it helps in understanding the data and the features that can be used in the ML model.\n",
    "\n",
    "## Major Variables explored are `age_at_marriage` and `level_of_education`\n",
    "First, I explored age at first marriage, as it directly reflects the concept of early marriage. By examining the distribution of this variable, I aimed to identify common age ranges at which individuals tend to marry, and whether certain patterns emerge, such as a higher frequency of early marriage within specific age groups. Additionally, I looked for potential outliers or any skew in the data that might indicate extreme cases of early marriage.\n",
    "\n",
    "Next, I focused on highest level of education, as education is often a significant predictor of marriage timing. I analyzed the relationship between education levels (e.g., primary, secondary, university) and age at first marriage. This helped in identifying whether individuals with lower levels of education tend to marry earlier, while those with higher education levels might delay marriage. The interaction between education and early marriage could provide insights into socio-economic factors that influence marital decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e187a62",
   "metadata": {},
   "source": [
    "## Histogram of age at first marriage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abandoned-cleveland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['age_at_marriage'], bins=10, kde=False, color='skyblue', edgecolor='black')\n",
    "\n",
    "plt.title('Histogram of Age at First Marriage')\n",
    "plt.xlabel('Age at First Marriage')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-workshop",
   "metadata": {},
   "source": [
    "The age at first marriage is skewed to the right with many individuals getting married about 20 years.A right-skewed histogram of age at first marriage indicates that most individuals are marrying at younger ages, but there is a long tail extending towards older ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "innocent-royal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Age at First Marriage by Highest Education Level\n",
      "+-------------------+--------------------+--------+---------+\n",
      "| highest_education |        mean        | median |  count  |\n",
      "+-------------------+--------------------+--------+---------+\n",
      "|     Preschool     | 20.23346382767661  |  19.0  | 112904  |\n",
      "|  Primary-school   |  20.4047519741933  |  20.0  | 4457137 |\n",
      "|     Secondary     | 21.609568584169892 |  20.0  | 2790695 |\n",
      "| Technical college | 23.140605523160968 |  22.0  | 119533  |\n",
      "|    University     | 25.30795173033027  |  25.0  | 369756  |\n",
      "+-------------------+--------------------+--------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Mapping for the education levels\n",
    "education_mapping = {\n",
    "    1: 'Preschool',\n",
    "    2: 'Primary-school',\n",
    "    3: 'Secondary',\n",
    "    4: 'Technical college',\n",
    "    5: 'University'\n",
    "}\n",
    "\n",
    "education_age_grouped = df.groupby('highest_education')['age_at_marriage'].agg(\n",
    "    ['mean', 'median','count']\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "education_age_grouped['highest_education'] = education_age_grouped['highest_education'].map(education_mapping)\n",
    "\n",
    "print(\"Summary of Age at First Marriage by Highest Education Level\")\n",
    "print(tabulate(education_age_grouped, headers='keys', tablefmt='pretty', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-brain",
   "metadata": {},
   "source": [
    "The table above shows a clear trend between education level and the age at first marriage. Individuals with only preschool education marry the earliest, with an average age of around 20.2 years. As education increases, the age at first marriage also rises. Those with primary-school education marry at an average age of 20.4, while individuals with secondary education marry slightly later, at 21.6 years on average.\n",
    "\n",
    "For those with technical college education, the average age increases further to 23.1 years, and university graduates have the latest average age at first marriage at 25.3 years. This trend suggests that higher levels of education are associated with a delay in marriage, likely due to factors like career and financial stability. In contrast, lower education levels are linked to earlier marriages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-parent",
   "metadata": {},
   "source": [
    "# Task-4-Prepare data for ML model building\n",
    "\n",
    "To predict early marriage, the target variable is created from age at first marriage. A threshold age, such as 20 years, is used to define early marriage. If someone marries at or before this age, the target variable is assigned a value of 1 (early marriage). If they marry after this age, the target variable is assigned a value of 0 (late marriage). This converts the age at first marriage into a binary classification variable.\n",
    "\n",
    "In order to gain an initial understanding of which variables might be important for classification, I used a Random Forest model with 10 trees. This helped me get a rough idea of the variables that could potentially be useful in predicting early marriage, even though the results were not highly accurate. The Random Forest model provided an overview of the feature importances, giving me insight into which variables were likely contributing the most to the classification task. While this approach didn't provide precise feature rankings, it served as a useful starting point to identify the key features that might be worth further exploration and refinement in the modeling process. \n",
    "\n",
    "As for communes, their inclusion depends on their significance. If communes represent smaller geographic units with distinct socio-cultural characteristics that influence marriage timing, they could provide valuable insights. However, if the number of communes is large or their information overlaps with districts or regions, it might introduce redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1fa0e",
   "metadata": {},
   "source": [
    "# Prepare Data for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1a6f1",
   "metadata": {},
   "source": [
    "## Generate Target Variable for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "781213e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# ADD EARLY MARRIAGE VARIABLE\n",
    "# ====================================\n",
    "# if age_married < 18, then early_marriage = 1\n",
    "df['early_marriage'] = df['age_at_marriage'].apply(lambda x: 1 if x < EARLY_MARRIAGE_AGE_THRESHOLD else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d8c3a2",
   "metadata": {},
   "source": [
    "## Drop Observations\n",
    "- In this datasets, the marriage variabels are available for all individuals who are 12 years old or older. We can drop the observations where the marriage status is not available.\n",
    "- Age at first marriage also makes sense for people who are currently married, divorced or widowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43779b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only individuals who are 12 years and above\n",
    "df_marr = df[df['age'] >= 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85cfa90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only individuals who were ever married (currently married, divorced or widowed)\n",
    "df_marr = df_marr[df_marr['marital_status'] != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048bdf11",
   "metadata": {},
   "source": [
    "## Features for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "337bdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2int(x):\n",
    "    try:\n",
    "        # Check if value is a float and has no decimal part\n",
    "        if isinstance(x, float) and x.is_integer():\n",
    "            return int(x)\n",
    "        elif isinstance(x, int):  # Handle integers directly\n",
    "            return x\n",
    "        else:\n",
    "            return np.nan  # Return NaN for anything else\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "swiss-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to apply the conversion to (float columns that should be integers)\n",
    "columns_to_convert = [\n",
    "    'age', 'marital_status', 'working_status', 'highest_education', \n",
    "    'years_completed', 'school_attendance', 'age_at_marriage', \n",
    "    'local_lnguage', 'french', 'english', 'other_language', \n",
    "    'local_language_literacy', 'french_literacy', 'english_literacy', \n",
    "    'other_language_literacy',\n",
    "]\n",
    "\n",
    "# Apply the conversion to those columns\n",
    "df_marr[columns_to_convert] = df_marr[columns_to_convert].applymap(convert2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b2d92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# PREPARE DATA FOR ML MODELS\n",
    "# ====================================\n",
    "# Convert columns with categorical data to pd.category type.\n",
    "# Ensure that the categorical columns are of type int\n",
    "\n",
    "# Target variable for prediction\n",
    "target_variable = 'early_marriage'\n",
    "\n",
    "# Features to use for prediction\n",
    "feature_columns = [\n",
    "    'PROVINCE', 'REGION', 'DISTRICT', 'COMMUNE', \n",
    "    'marital_status', 'sex', 'highest_education','school_attendance','num_children',\n",
    "    'num_elderly'\n",
    "]\n",
    "# Set categorical features to pd.Categorical\n",
    "# Convert columns to categorical\n",
    "categorical_columns = ['MILIEU','marital_status', 'working_status','head_household', 'highest_education', 'school_attendance',\n",
    "                      'local_language_literacy', 'french_literacy', 'english_literacy', 'other_language_literacy',\n",
    "                      'local_lnguage', 'french', 'english', 'other_language', 'sex', 'is_child', 'is_elderly','years_completed']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df_marr[col] = pd.Categorical(df_marr[col])\n",
    "    \n",
    "for col in categorical_columns:\n",
    "    df_marr[col] = df_marr[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f462528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# DEAL WITH MISSING VALUES\n",
    "# ====================================\n",
    "# Fill missing values with the mode for categorical variables\n",
    "# and mean/median for continuous variables\n",
    "continuous_columns = ['age', 'age_at_marriage']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    mode_value = df_marr[col].mode()[0]  # Get the most frequent value (mode)\n",
    "    df_marr[col].fillna(mode_value, inplace=True)\n",
    "    \n",
    "for col in continuous_columns:\n",
    "    if df_marr[col].dtype == 'float64' or df_marr[col].dtype == 'int64':\n",
    "        median_value = df_marr[col].median()  # Use median for continuous variables\n",
    "        df_marr[col].fillna(median_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e9f1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEAL WITH OUTLIERS IN CONTINUOUS VARIABLES\n",
    "# =============================================\n",
    "# Age, drop all observations with age > 100\n",
    "df_marr = df_marr[df_marr['age'] <= 100]\n",
    "\n",
    "# HH_SIZE, drop all observations with hh_size > 20\n",
    "df_marr = df_marr[df_marr['hh_size'] <= 20]\n",
    "\n",
    "# NUM_CHILDREN, drop all observations with num_children > 15\n",
    "df_marr = df_marr[df_marr['num_children'] <= 15]\n",
    "\n",
    "# NUM_ELDERLY, drop all observations with num_elderly > 15\n",
    "df_marr = df_marr[df_marr['num_elderly'] <= 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beb7b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ONE-HOT ENCODING FOR CATEGORICAL VARIABLES\n",
    "# ============================================\n",
    "# One-hot encode the categorical variables\n",
    "# using pd.get_dummies function\n",
    "# Make sure you one-hot encode all the categorical variables\n",
    "df_encoded = pd.get_dummies(df_marr, columns=categorical_columns, drop_first=True)\n",
    "# Convert True/False to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "constant-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Important Features:\n",
      "                      Feature  Importance\n",
      "7             age_at_marriage        0.84\n",
      "6                         age        0.05\n",
      "54                      sex_1        0.02\n",
      "21           head_household_1        0.02\n",
      "3                     COMMUNE        0.01\n",
      "4                       hh_id        0.01\n",
      "2                    DISTRICT        0.01\n",
      "38  local_language_literacy_0        0.00\n",
      "39  local_language_literacy_1        0.00\n",
      "5                    indiv_id        0.00\n",
      "9                num_children        0.00\n",
      "8                     hh_size        0.00\n",
      "35        school_attendance_1        0.00\n",
      "0                    PROVINCE        0.00\n",
      "11                   MILIEU_1        0.00\n",
      "41          french_literacy_1        0.00\n",
      "16           working_status_3        0.00\n",
      "31        highest_education_1        0.00\n",
      "48                   french_0        0.00\n",
      "50                  english_0        0.00\n"
     ]
    }
   ],
   "source": [
    "target = 'early_marriage'\n",
    "\n",
    "X = df_encoded.drop(columns=[target])\n",
    "y = df_encoded[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RF(n_estimators=10, random_state=42) \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names and their importance scores\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance and get the top 20 most important features\n",
    "top_20_features = features_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "# Print the top 20 most important features\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(top_20_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "liked-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = ['age', 'sex_1', 'head_household_1', 'COMMUNE', 'DISTRICT','french_literacy_1','hh_size',\n",
    "                     'working_status_3','MILIEU_1', 'highest_education_3', 'french_1','early_marriage']\n",
    "\n",
    "df_important_features = df_encoded[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "white-mount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age  sex_1  head_household_1  COMMUNE  DISTRICT  french_literacy_1  \\\n",
      "6          49      1                 1    11101       111                  0   \n",
      "8          77      1                 0    11101       111                  0   \n",
      "9          18      1                 0    11101       111                  0   \n",
      "11         45      1                 1    11101       111                  0   \n",
      "15         43      0                 0    11101       111                  0   \n",
      "...       ...    ...               ...      ...       ...                ...   \n",
      "25674184   35      1                 1    62414       624                  1   \n",
      "25674187   31      1                 0    62418       624                  0   \n",
      "25674188   18      1                 1    62418       624                  1   \n",
      "25674190   55      1                 1    62416       624                  1   \n",
      "25674193   25      1                 1    62413       624                  1   \n",
      "\n",
      "          hh_size  working_status_3  MILIEU_1  highest_education_3  french_1  \\\n",
      "6               3                 0         0                    0         0   \n",
      "8               6                 0         0                    0         0   \n",
      "9               6                 0         0                    0         0   \n",
      "11              8                 0         0                    0         0   \n",
      "15              3                 0         0                    0         0   \n",
      "...           ...               ...       ...                  ...       ...   \n",
      "25674184        6                 0         1                    0         1   \n",
      "25674187        3                 0         1                    0         1   \n",
      "25674188        2                 0         1                    0         1   \n",
      "25674190        2                 0         1                    0         1   \n",
      "25674193        4                 0         1                    0         1   \n",
      "\n",
      "          early_marriage  \n",
      "6                      0  \n",
      "8                      0  \n",
      "9                      1  \n",
      "11                     0  \n",
      "15                     0  \n",
      "...                  ...  \n",
      "25674184               0  \n",
      "25674187               1  \n",
      "25674188               1  \n",
      "25674190               1  \n",
      "25674193               0  \n",
      "\n",
      "[10510524 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-membrane",
   "metadata": {},
   "source": [
    "# Task 5 - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78f9a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_with_sklearn(df_encoded, num_estimators=100):\n",
    "    # Define the target variable and features\n",
    "    target_var = 'early_marriage'\n",
    "    features = df_important_features.columns[df_important_features.columns != target_var]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X = df_important_features[features]\n",
    "    y = df_important_features[target_var]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest model\n",
    "    rf_model = RF(n_estimators=num_estimators, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "better-angle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7930157638786258\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87   2446357\n",
      "           1       0.55      0.42      0.48    706801\n",
      "\n",
      "    accuracy                           0.79   3153158\n",
      "   macro avg       0.70      0.66      0.67   3153158\n",
      "weighted avg       0.78      0.79      0.78   3153158\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_with_sklearn(df_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58459c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_sklearn(df_important_features):\n",
    "    # Define the target variable and features\n",
    "    target_var = 'early_marriage'\n",
    "    features = df_important_features.columns[df_important_features.columns != target_var]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X = df_important_features[features]\n",
    "    y = df_important_features[target_var]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Initialize the models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LR(max_iter=100, random_state=42,solver='saga'),\n",
    "        \"Random Forest\": RF(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        \"Gradient Boosting\": GBM(n_estimators=100, random_state=42),\n",
    "        \"Extra Trees\": ETC(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    }\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append([name, accuracy])\n",
    "\n",
    "    # Print the results in a tabular format\n",
    "    print(tabulate(results, headers=[\"Model\", \"Accuracy\"], tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b77dfc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+\n",
      "|        Model        |      Accuracy      |\n",
      "+---------------------+--------------------+\n",
      "| Logistic Regression | 0.7793856191158197 |\n",
      "|    Random Forest    | 0.7930157638786258 |\n",
      "|  Gradient Boosting  | 0.815785951734737  |\n",
      "|     Extra Trees     | 0.7938609482937423 |\n",
      "+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Build and evaluate the models using the df_marr2_dummies DataFrame\n",
    "evaluate_models_sklearn(df_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad2b00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "def evaluate_models_spark(df_important_features, target_var):\n",
    "    \"\"\"\n",
    "    Evaluate multiple machine learning models using Spark MLlib on the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pyspark.sql.DataFrame\n",
    "        The input DataFrame containing features and the target variable.\n",
    "    target_var : str\n",
    "        The name of the target variable column.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Define the features\n",
    "    features = [col for col in df_important_features.columns if col != target_var]\n",
    "\n",
    "    # Assemble features into a single vector\n",
    "    assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "    df_important_features = assembler.transform(df_important_features).select(\"features\", target_var)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_df, test_df = df_important_features.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "    \"Logistic Regression\": LogisticRegression(maxIter=25).setFeaturesCol(\"features\").setLabelCol(target_var),\n",
    "    \"Random Forest\": RandomForestClassifier(numTrees=50, seed=42).setFeaturesCol(\"features\").setLabelCol(target_var),\n",
    "    \"Gradient Boosting\": GBTClassifier(maxIter=50, seed=42).setFeaturesCol(\"features\").setLabelCol(target_var),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(seed=42).setFeaturesCol(\"features\").setLabelCol(target_var),\n",
    "}\n",
    "\n",
    "    # Initialize evaluator\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=target_var, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        # Train the model\n",
    "        trained_model = model.fit(train_df)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = trained_model.transform(test_df)\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "        # Append results\n",
    "        results.append([name, accuracy])\n",
    "\n",
    "    # Print results in a tabular format\n",
    "    from tabulate import tabulate\n",
    "    print(tabulate(results, headers=[\"Model\", \"Accuracy\"], tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "severe-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas DataFrame to PySpark DataFrame\n",
    "df_spark = spark.createDataFrame(df_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc6c2e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+\n",
      "|        Model        |      Accuracy      |\n",
      "+---------------------+--------------------+\n",
      "| Logistic Regression | 0.7989872746402189 |\n",
      "|    Random Forest    | 0.8014321778828876 |\n",
      "|  Gradient Boosting  | 0.8152337645324725 |\n",
      "|    Decision Tree    | 0.8031247056077034 |\n",
      "+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "evaluate_models_spark(df_spark, \"early_marriage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-dominant",
   "metadata": {},
   "source": [
    "# Task 5 - -Build ML Model with Scikit-learn and spark - Discussion\n",
    "The results from the models indicate solid performance, with Gradient Boosting achieving the highest accuracy at 81.53%, followed closely by Decision Tree at 80.34% and Random Forest at 80.14%. These ensemble models perform better than Logistic Regression, which had the lowest accuracy at 79.89%. This suggests that models like Gradient Boosting and Random Forest, which can handle complex patterns and non-linear relationships, are more effective for predicting early marriage compared to simpler models like Logistic Regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "blocked-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare the features\n",
    "feature_columns = ['age', 'sex_1', 'head_household_1', 'COMMUNE', 'DISTRICT','french_literacy_1','hh_size',\n",
    "                     'working_status_3','MILIEU_1', 'highest_education_3', 'french_1','early_marriage']  # Example features\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Define the GBT model\n",
    "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"early_marriage\", maxIter=10)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, gbt])\n",
    "\n",
    "# Fit the model\n",
    "model = pipeline.fit(df_spark)\n",
    "gbt_model = model.stages[-1]\n",
    "\n",
    "# Get feature importances\n",
    "importances = gbt_model.featureImportances\n",
    "\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': importances.toArray()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "higher-guidance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11         early_marriage\n",
      "6                 hh_size\n",
      "1                   sex_1\n",
      "2        head_household_1\n",
      "3                 COMMUNE\n",
      "9     highest_education_3\n",
      "Name: Feature, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Sort by importance and get top 5 features\n",
    "top_5_features = feature_importances.sort_values(by='Importance', ascending=False).head(6)\n",
    "\n",
    "print(top_5_features['Feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-tennessee",
   "metadata": {},
   "source": [
    "The top 5 predictors of early marriage are as follows: household size (hh_size), which suggests that larger households may be associated with earlier marriages; sex_1, where being male is linked to a higher likelihood of early marriage; head_household_1, indicating that individuals who are heads of their households tend to marry earlier, possibly due to increased responsibility; COMMUNE, which reflects the geographic region and its influence on marriage practices; and highest_education_3, where having a secondary level of education is a key factor, with those possessing this level of education often marrying at a younger age."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
